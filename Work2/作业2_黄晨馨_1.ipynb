{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from torch.utils.data import TensorDataset\n",
    "from torchvision import transforms\n",
    "import os\n",
    "import copy\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#读取数据\n",
    "TrainData = 'TrainData.csv'\n",
    "TestData = 'TestData.csv'\n",
    "\n",
    "traindata = pd.read_csv(TrainData)\n",
    "testdata = pd.read_csv(TestData)\n",
    "\n",
    "trainData = np.array(traindata)[:,:4]\n",
    "trainLable = np.array(traindata)[:,-1]\n",
    "trainData = torch.tensor(trainData).float()\n",
    "trainLable = torch.tensor(trainLable).long()#改成long形式，不然后面会出错\n",
    "\n",
    "testData = np.array(testdata)[:,:4]\n",
    "testLable = np.array(testdata)[:,-1]\n",
    "testData = torch.tensor(testData).float()\n",
    "testLable = torch.tensor(testLable).long()\n",
    "\n",
    "epochs = 200#迭代200次\n",
    "batch = 10#最开始batchsize设置为10\n",
    "####参考，对tensor进行打包合并\n",
    "train_ds = TensorDataset(trainData,trainLable)\n",
    "###参考，打乱训练集数据顺序，希望模型不关注顺序\n",
    "train = DataLoader(train_ds,batch_size = batch,shuffle = True)\n",
    "\n",
    "test_ds = TensorDataset(testData,testLable)\n",
    "test = DataLoader(train_ds,batch_size = batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "##创建模型\n",
    "##继承nn.Module这个类并自定义模型\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net,self).__init__()\n",
    "        ##输入到隐藏层，4个输入特征，64个输出特征\n",
    "        self.hidden = nn.Sequential(nn.Linear(4,64),nn.ReLU(inplace = True))\n",
    "        ##输入到输出层，64个输入特征，3个输出特征\n",
    "        self.predict = nn.Linear(64,3)\n",
    "\n",
    "    def forward(self,input):##搭建的前馈神经网络,调用上述的层处理输入\n",
    "        ##隐藏层对输入进行调用，并使用激活函数\n",
    "        x = self.hidden(input)\n",
    "        ##多分类不用激活\n",
    "        out = self.predict(x)\n",
    "        \n",
    "        return out\n",
    "    \n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "##损失函数\n",
    "loss_func = nn.CrossEntropyLoss()##交叉熵\n",
    "\n",
    "###准确率、混淆矩阵……\n",
    "def accuracy(test_out,testLable):\n",
    "    test_predict = torch.argmax(test_out,dim = 1)#?\n",
    "    accuracy = (test_predict == testLable).float().mean()\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "##优化算法\n",
    "from torch import optim\n",
    "optimizer = optim.Adam(net.parameters(),lr = 0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  0 train_loss:  1.223 train_accuracy:  0.0 test_loss:  1.209 test_accuracy:  0.0\n",
      "epoch:  1 train_loss:  1.201 train_accuracy:  0.0 test_loss:  1.189 test_accuracy:  0.0\n",
      "epoch:  2 train_loss:  1.181 train_accuracy:  0.0 test_loss:  1.171 test_accuracy:  0.0\n",
      "epoch:  3 train_loss:  1.164 train_accuracy:  0.0 test_loss:  1.155 test_accuracy:  0.0\n",
      "epoch:  4 train_loss:  1.147 train_accuracy:  0.217 test_loss:  1.139 test_accuracy:  0.267\n",
      "epoch:  5 train_loss:  1.132 train_accuracy:  0.333 test_loss:  1.125 test_accuracy:  0.333\n",
      "epoch:  6 train_loss:  1.118 train_accuracy:  0.333 test_loss:  1.112 test_accuracy:  0.333\n",
      "epoch:  7 train_loss:  1.104 train_accuracy:  0.333 test_loss:  1.099 test_accuracy:  0.333\n",
      "epoch:  8 train_loss:  1.091 train_accuracy:  0.333 test_loss:  1.087 test_accuracy:  0.333\n",
      "epoch:  9 train_loss:  1.078 train_accuracy:  0.333 test_loss:  1.075 test_accuracy:  0.333\n",
      "epoch:  10 train_loss:  1.065 train_accuracy:  0.333 test_loss:  1.063 test_accuracy:  0.333\n",
      "epoch:  11 train_loss:  1.053 train_accuracy:  0.333 test_loss:  1.051 test_accuracy:  0.333\n",
      "epoch:  12 train_loss:  1.04 train_accuracy:  0.333 test_loss:  1.039 test_accuracy:  0.333\n",
      "epoch:  13 train_loss:  1.028 train_accuracy:  0.333 test_loss:  1.028 test_accuracy:  0.333\n",
      "epoch:  14 train_loss:  1.015 train_accuracy:  0.342 test_loss:  1.016 test_accuracy:  0.333\n",
      "epoch:  15 train_loss:  1.003 train_accuracy:  0.375 test_loss:  1.005 test_accuracy:  0.4\n",
      "epoch:  16 train_loss:  0.991 train_accuracy:  0.592 test_loss:  0.994 test_accuracy:  0.567\n",
      "epoch:  17 train_loss:  0.98 train_accuracy:  0.642 test_loss:  0.983 test_accuracy:  0.667\n",
      "epoch:  18 train_loss:  0.968 train_accuracy:  0.667 test_loss:  0.972 test_accuracy:  0.667\n",
      "epoch:  19 train_loss:  0.956 train_accuracy:  0.667 test_loss:  0.961 test_accuracy:  0.667\n",
      "epoch:  20 train_loss:  0.945 train_accuracy:  0.667 test_loss:  0.95 test_accuracy:  0.667\n",
      "epoch:  21 train_loss:  0.934 train_accuracy:  0.667 test_loss:  0.939 test_accuracy:  0.667\n",
      "epoch:  22 train_loss:  0.922 train_accuracy:  0.667 test_loss:  0.929 test_accuracy:  0.667\n",
      "epoch:  23 train_loss:  0.912 train_accuracy:  0.667 test_loss:  0.919 test_accuracy:  0.667\n",
      "epoch:  24 train_loss:  0.901 train_accuracy:  0.667 test_loss:  0.908 test_accuracy:  0.667\n",
      "epoch:  25 train_loss:  0.89 train_accuracy:  0.667 test_loss:  0.898 test_accuracy:  0.667\n",
      "epoch:  26 train_loss:  0.88 train_accuracy:  0.667 test_loss:  0.889 test_accuracy:  0.667\n",
      "epoch:  27 train_loss:  0.869 train_accuracy:  0.667 test_loss:  0.879 test_accuracy:  0.667\n",
      "epoch:  28 train_loss:  0.859 train_accuracy:  0.667 test_loss:  0.869 test_accuracy:  0.667\n",
      "epoch:  29 train_loss:  0.849 train_accuracy:  0.667 test_loss:  0.86 test_accuracy:  0.667\n",
      "epoch:  30 train_loss:  0.84 train_accuracy:  0.667 test_loss:  0.85 test_accuracy:  0.667\n",
      "epoch:  31 train_loss:  0.83 train_accuracy:  0.667 test_loss:  0.841 test_accuracy:  0.667\n",
      "epoch:  32 train_loss:  0.821 train_accuracy:  0.667 test_loss:  0.832 test_accuracy:  0.667\n",
      "epoch:  33 train_loss:  0.812 train_accuracy:  0.667 test_loss:  0.823 test_accuracy:  0.667\n",
      "epoch:  34 train_loss:  0.803 train_accuracy:  0.667 test_loss:  0.815 test_accuracy:  0.667\n",
      "epoch:  35 train_loss:  0.794 train_accuracy:  0.667 test_loss:  0.806 test_accuracy:  0.667\n",
      "epoch:  36 train_loss:  0.786 train_accuracy:  0.667 test_loss:  0.798 test_accuracy:  0.667\n",
      "epoch:  37 train_loss:  0.777 train_accuracy:  0.667 test_loss:  0.79 test_accuracy:  0.667\n",
      "epoch:  38 train_loss:  0.769 train_accuracy:  0.667 test_loss:  0.782 test_accuracy:  0.667\n",
      "epoch:  39 train_loss:  0.761 train_accuracy:  0.667 test_loss:  0.774 test_accuracy:  0.667\n",
      "epoch:  40 train_loss:  0.753 train_accuracy:  0.667 test_loss:  0.766 test_accuracy:  0.667\n",
      "epoch:  41 train_loss:  0.746 train_accuracy:  0.667 test_loss:  0.759 test_accuracy:  0.667\n",
      "epoch:  42 train_loss:  0.738 train_accuracy:  0.675 test_loss:  0.752 test_accuracy:  0.667\n",
      "epoch:  43 train_loss:  0.731 train_accuracy:  0.675 test_loss:  0.744 test_accuracy:  0.667\n",
      "epoch:  44 train_loss:  0.724 train_accuracy:  0.675 test_loss:  0.738 test_accuracy:  0.667\n",
      "epoch:  45 train_loss:  0.717 train_accuracy:  0.675 test_loss:  0.731 test_accuracy:  0.667\n",
      "epoch:  46 train_loss:  0.71 train_accuracy:  0.675 test_loss:  0.724 test_accuracy:  0.667\n",
      "epoch:  47 train_loss:  0.704 train_accuracy:  0.675 test_loss:  0.717 test_accuracy:  0.667\n",
      "epoch:  48 train_loss:  0.697 train_accuracy:  0.675 test_loss:  0.711 test_accuracy:  0.667\n",
      "epoch:  49 train_loss:  0.691 train_accuracy:  0.675 test_loss:  0.705 test_accuracy:  0.667\n",
      "epoch:  50 train_loss:  0.685 train_accuracy:  0.675 test_loss:  0.699 test_accuracy:  0.667\n",
      "epoch:  51 train_loss:  0.679 train_accuracy:  0.675 test_loss:  0.692 test_accuracy:  0.667\n",
      "epoch:  52 train_loss:  0.673 train_accuracy:  0.675 test_loss:  0.687 test_accuracy:  0.667\n",
      "epoch:  53 train_loss:  0.667 train_accuracy:  0.675 test_loss:  0.681 test_accuracy:  0.7\n",
      "epoch:  54 train_loss:  0.661 train_accuracy:  0.692 test_loss:  0.675 test_accuracy:  0.7\n",
      "epoch:  55 train_loss:  0.656 train_accuracy:  0.692 test_loss:  0.67 test_accuracy:  0.7\n",
      "epoch:  56 train_loss:  0.65 train_accuracy:  0.692 test_loss:  0.664 test_accuracy:  0.7\n",
      "epoch:  57 train_loss:  0.645 train_accuracy:  0.692 test_loss:  0.659 test_accuracy:  0.7\n",
      "epoch:  58 train_loss:  0.64 train_accuracy:  0.742 test_loss:  0.654 test_accuracy:  0.7\n",
      "epoch:  59 train_loss:  0.634 train_accuracy:  0.742 test_loss:  0.649 test_accuracy:  0.7\n",
      "epoch:  60 train_loss:  0.63 train_accuracy:  0.742 test_loss:  0.644 test_accuracy:  0.7\n",
      "epoch:  61 train_loss:  0.625 train_accuracy:  0.75 test_loss:  0.639 test_accuracy:  0.7\n",
      "epoch:  62 train_loss:  0.62 train_accuracy:  0.742 test_loss:  0.634 test_accuracy:  0.7\n",
      "epoch:  63 train_loss:  0.615 train_accuracy:  0.767 test_loss:  0.629 test_accuracy:  0.733\n",
      "epoch:  64 train_loss:  0.611 train_accuracy:  0.775 test_loss:  0.625 test_accuracy:  0.767\n",
      "epoch:  65 train_loss:  0.606 train_accuracy:  0.775 test_loss:  0.62 test_accuracy:  0.767\n",
      "epoch:  66 train_loss:  0.602 train_accuracy:  0.775 test_loss:  0.616 test_accuracy:  0.733\n",
      "epoch:  67 train_loss:  0.598 train_accuracy:  0.775 test_loss:  0.612 test_accuracy:  0.767\n",
      "epoch:  68 train_loss:  0.594 train_accuracy:  0.775 test_loss:  0.607 test_accuracy:  0.767\n",
      "epoch:  69 train_loss:  0.59 train_accuracy:  0.783 test_loss:  0.603 test_accuracy:  0.8\n",
      "epoch:  70 train_loss:  0.586 train_accuracy:  0.792 test_loss:  0.599 test_accuracy:  0.8\n",
      "epoch:  71 train_loss:  0.582 train_accuracy:  0.783 test_loss:  0.595 test_accuracy:  0.8\n",
      "epoch:  72 train_loss:  0.578 train_accuracy:  0.783 test_loss:  0.591 test_accuracy:  0.8\n",
      "epoch:  73 train_loss:  0.574 train_accuracy:  0.783 test_loss:  0.588 test_accuracy:  0.8\n",
      "epoch:  74 train_loss:  0.571 train_accuracy:  0.792 test_loss:  0.584 test_accuracy:  0.8\n",
      "epoch:  75 train_loss:  0.567 train_accuracy:  0.8 test_loss:  0.58 test_accuracy:  0.8\n",
      "epoch:  76 train_loss:  0.564 train_accuracy:  0.825 test_loss:  0.577 test_accuracy:  0.833\n",
      "epoch:  77 train_loss:  0.56 train_accuracy:  0.825 test_loss:  0.573 test_accuracy:  0.833\n",
      "epoch:  78 train_loss:  0.557 train_accuracy:  0.825 test_loss:  0.57 test_accuracy:  0.833\n",
      "epoch:  79 train_loss:  0.553 train_accuracy:  0.825 test_loss:  0.566 test_accuracy:  0.833\n",
      "epoch:  80 train_loss:  0.55 train_accuracy:  0.825 test_loss:  0.563 test_accuracy:  0.833\n",
      "epoch:  81 train_loss:  0.547 train_accuracy:  0.833 test_loss:  0.559 test_accuracy:  0.867\n",
      "epoch:  82 train_loss:  0.544 train_accuracy:  0.825 test_loss:  0.556 test_accuracy:  0.833\n",
      "epoch:  83 train_loss:  0.541 train_accuracy:  0.825 test_loss:  0.553 test_accuracy:  0.833\n",
      "epoch:  84 train_loss:  0.538 train_accuracy:  0.825 test_loss:  0.55 test_accuracy:  0.833\n",
      "epoch:  85 train_loss:  0.535 train_accuracy:  0.833 test_loss:  0.547 test_accuracy:  0.867\n",
      "epoch:  86 train_loss:  0.532 train_accuracy:  0.833 test_loss:  0.544 test_accuracy:  0.867\n",
      "epoch:  87 train_loss:  0.529 train_accuracy:  0.825 test_loss:  0.541 test_accuracy:  0.833\n",
      "epoch:  88 train_loss:  0.526 train_accuracy:  0.833 test_loss:  0.538 test_accuracy:  0.867\n",
      "epoch:  89 train_loss:  0.523 train_accuracy:  0.833 test_loss:  0.535 test_accuracy:  0.867\n",
      "epoch:  90 train_loss:  0.52 train_accuracy:  0.867 test_loss:  0.532 test_accuracy:  0.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  91 train_loss:  0.518 train_accuracy:  0.867 test_loss:  0.529 test_accuracy:  0.9\n",
      "epoch:  92 train_loss:  0.515 train_accuracy:  0.867 test_loss:  0.526 test_accuracy:  0.9\n",
      "epoch:  93 train_loss:  0.512 train_accuracy:  0.867 test_loss:  0.523 test_accuracy:  0.9\n",
      "epoch:  94 train_loss:  0.51 train_accuracy:  0.858 test_loss:  0.521 test_accuracy:  0.9\n",
      "epoch:  95 train_loss:  0.507 train_accuracy:  0.867 test_loss:  0.518 test_accuracy:  0.9\n",
      "epoch:  96 train_loss:  0.505 train_accuracy:  0.867 test_loss:  0.515 test_accuracy:  0.9\n",
      "epoch:  97 train_loss:  0.502 train_accuracy:  0.867 test_loss:  0.513 test_accuracy:  0.9\n",
      "epoch:  98 train_loss:  0.5 train_accuracy:  0.867 test_loss:  0.51 test_accuracy:  0.9\n",
      "epoch:  99 train_loss:  0.497 train_accuracy:  0.867 test_loss:  0.508 test_accuracy:  0.9\n",
      "epoch:  100 train_loss:  0.495 train_accuracy:  0.867 test_loss:  0.505 test_accuracy:  0.9\n",
      "epoch:  101 train_loss:  0.493 train_accuracy:  0.867 test_loss:  0.503 test_accuracy:  0.9\n",
      "epoch:  102 train_loss:  0.49 train_accuracy:  0.867 test_loss:  0.5 test_accuracy:  0.933\n",
      "epoch:  103 train_loss:  0.488 train_accuracy:  0.883 test_loss:  0.498 test_accuracy:  0.933\n",
      "epoch:  104 train_loss:  0.486 train_accuracy:  0.9 test_loss:  0.496 test_accuracy:  0.933\n",
      "epoch:  105 train_loss:  0.483 train_accuracy:  0.883 test_loss:  0.493 test_accuracy:  0.933\n",
      "epoch:  106 train_loss:  0.481 train_accuracy:  0.892 test_loss:  0.491 test_accuracy:  0.933\n",
      "epoch:  107 train_loss:  0.479 train_accuracy:  0.9 test_loss:  0.489 test_accuracy:  0.933\n",
      "epoch:  108 train_loss:  0.477 train_accuracy:  0.9 test_loss:  0.486 test_accuracy:  0.967\n",
      "epoch:  109 train_loss:  0.475 train_accuracy:  0.9 test_loss:  0.484 test_accuracy:  0.967\n",
      "epoch:  110 train_loss:  0.473 train_accuracy:  0.9 test_loss:  0.482 test_accuracy:  0.967\n",
      "epoch:  111 train_loss:  0.471 train_accuracy:  0.9 test_loss:  0.48 test_accuracy:  0.933\n",
      "epoch:  112 train_loss:  0.468 train_accuracy:  0.9 test_loss:  0.478 test_accuracy:  0.967\n",
      "epoch:  113 train_loss:  0.466 train_accuracy:  0.9 test_loss:  0.475 test_accuracy:  0.967\n",
      "epoch:  114 train_loss:  0.464 train_accuracy:  0.9 test_loss:  0.473 test_accuracy:  0.967\n",
      "epoch:  115 train_loss:  0.462 train_accuracy:  0.9 test_loss:  0.471 test_accuracy:  0.967\n",
      "epoch:  116 train_loss:  0.46 train_accuracy:  0.9 test_loss:  0.469 test_accuracy:  0.967\n",
      "epoch:  117 train_loss:  0.458 train_accuracy:  0.917 test_loss:  0.467 test_accuracy:  0.967\n",
      "epoch:  118 train_loss:  0.456 train_accuracy:  0.9 test_loss:  0.465 test_accuracy:  0.967\n",
      "epoch:  119 train_loss:  0.454 train_accuracy:  0.9 test_loss:  0.463 test_accuracy:  0.967\n",
      "epoch:  120 train_loss:  0.453 train_accuracy:  0.9 test_loss:  0.461 test_accuracy:  0.967\n",
      "epoch:  121 train_loss:  0.451 train_accuracy:  0.9 test_loss:  0.459 test_accuracy:  0.967\n",
      "epoch:  122 train_loss:  0.449 train_accuracy:  0.917 test_loss:  0.457 test_accuracy:  0.967\n",
      "epoch:  123 train_loss:  0.447 train_accuracy:  0.917 test_loss:  0.455 test_accuracy:  0.967\n",
      "epoch:  124 train_loss:  0.445 train_accuracy:  0.9 test_loss:  0.453 test_accuracy:  0.967\n",
      "epoch:  125 train_loss:  0.443 train_accuracy:  0.917 test_loss:  0.451 test_accuracy:  0.967\n",
      "epoch:  126 train_loss:  0.442 train_accuracy:  0.933 test_loss:  0.449 test_accuracy:  0.967\n",
      "epoch:  127 train_loss:  0.44 train_accuracy:  0.933 test_loss:  0.447 test_accuracy:  0.967\n",
      "epoch:  128 train_loss:  0.438 train_accuracy:  0.933 test_loss:  0.445 test_accuracy:  0.967\n",
      "epoch:  129 train_loss:  0.436 train_accuracy:  0.933 test_loss:  0.443 test_accuracy:  0.967\n",
      "epoch:  130 train_loss:  0.434 train_accuracy:  0.933 test_loss:  0.441 test_accuracy:  0.967\n",
      "epoch:  131 train_loss:  0.433 train_accuracy:  0.925 test_loss:  0.439 test_accuracy:  0.967\n",
      "epoch:  132 train_loss:  0.431 train_accuracy:  0.917 test_loss:  0.437 test_accuracy:  0.967\n",
      "epoch:  133 train_loss:  0.429 train_accuracy:  0.925 test_loss:  0.436 test_accuracy:  0.967\n",
      "epoch:  134 train_loss:  0.428 train_accuracy:  0.942 test_loss:  0.434 test_accuracy:  0.967\n",
      "epoch:  135 train_loss:  0.426 train_accuracy:  0.933 test_loss:  0.432 test_accuracy:  0.967\n",
      "epoch:  136 train_loss:  0.424 train_accuracy:  0.933 test_loss:  0.43 test_accuracy:  0.967\n",
      "epoch:  137 train_loss:  0.423 train_accuracy:  0.942 test_loss:  0.428 test_accuracy:  0.967\n",
      "epoch:  138 train_loss:  0.421 train_accuracy:  0.942 test_loss:  0.427 test_accuracy:  0.967\n",
      "epoch:  139 train_loss:  0.419 train_accuracy:  0.942 test_loss:  0.425 test_accuracy:  0.967\n",
      "epoch:  140 train_loss:  0.418 train_accuracy:  0.942 test_loss:  0.423 test_accuracy:  0.967\n",
      "epoch:  141 train_loss:  0.416 train_accuracy:  0.95 test_loss:  0.422 test_accuracy:  0.967\n",
      "epoch:  142 train_loss:  0.414 train_accuracy:  0.95 test_loss:  0.42 test_accuracy:  0.967\n",
      "epoch:  143 train_loss:  0.413 train_accuracy:  0.933 test_loss:  0.418 test_accuracy:  0.967\n",
      "epoch:  144 train_loss:  0.411 train_accuracy:  0.942 test_loss:  0.416 test_accuracy:  0.967\n",
      "epoch:  145 train_loss:  0.41 train_accuracy:  0.95 test_loss:  0.415 test_accuracy:  0.967\n",
      "epoch:  146 train_loss:  0.408 train_accuracy:  0.95 test_loss:  0.413 test_accuracy:  0.967\n",
      "epoch:  147 train_loss:  0.407 train_accuracy:  0.95 test_loss:  0.411 test_accuracy:  0.967\n",
      "epoch:  148 train_loss:  0.405 train_accuracy:  0.95 test_loss:  0.41 test_accuracy:  0.967\n",
      "epoch:  149 train_loss:  0.404 train_accuracy:  0.95 test_loss:  0.408 test_accuracy:  0.967\n",
      "epoch:  150 train_loss:  0.402 train_accuracy:  0.95 test_loss:  0.406 test_accuracy:  0.967\n",
      "epoch:  151 train_loss:  0.401 train_accuracy:  0.95 test_loss:  0.405 test_accuracy:  0.967\n",
      "epoch:  152 train_loss:  0.399 train_accuracy:  0.95 test_loss:  0.403 test_accuracy:  0.967\n",
      "epoch:  153 train_loss:  0.398 train_accuracy:  0.95 test_loss:  0.401 test_accuracy:  0.967\n",
      "epoch:  154 train_loss:  0.396 train_accuracy:  0.95 test_loss:  0.4 test_accuracy:  0.967\n",
      "epoch:  155 train_loss:  0.395 train_accuracy:  0.95 test_loss:  0.398 test_accuracy:  0.967\n",
      "epoch:  156 train_loss:  0.393 train_accuracy:  0.95 test_loss:  0.396 test_accuracy:  0.967\n",
      "epoch:  157 train_loss:  0.392 train_accuracy:  0.95 test_loss:  0.395 test_accuracy:  0.967\n",
      "epoch:  158 train_loss:  0.39 train_accuracy:  0.95 test_loss:  0.393 test_accuracy:  0.967\n",
      "epoch:  159 train_loss:  0.389 train_accuracy:  0.95 test_loss:  0.392 test_accuracy:  0.967\n",
      "epoch:  160 train_loss:  0.387 train_accuracy:  0.95 test_loss:  0.39 test_accuracy:  0.967\n",
      "epoch:  161 train_loss:  0.386 train_accuracy:  0.95 test_loss:  0.389 test_accuracy:  1.0\n",
      "epoch:  162 train_loss:  0.384 train_accuracy:  0.95 test_loss:  0.387 test_accuracy:  0.967\n",
      "epoch:  163 train_loss:  0.383 train_accuracy:  0.95 test_loss:  0.385 test_accuracy:  0.967\n",
      "epoch:  164 train_loss:  0.382 train_accuracy:  0.95 test_loss:  0.384 test_accuracy:  1.0\n",
      "epoch:  165 train_loss:  0.38 train_accuracy:  0.95 test_loss:  0.383 test_accuracy:  1.0\n",
      "epoch:  166 train_loss:  0.379 train_accuracy:  0.95 test_loss:  0.381 test_accuracy:  0.967\n",
      "epoch:  167 train_loss:  0.378 train_accuracy:  0.95 test_loss:  0.379 test_accuracy:  0.967\n",
      "epoch:  168 train_loss:  0.376 train_accuracy:  0.95 test_loss:  0.378 test_accuracy:  1.0\n",
      "epoch:  169 train_loss:  0.375 train_accuracy:  0.95 test_loss:  0.377 test_accuracy:  1.0\n",
      "epoch:  170 train_loss:  0.374 train_accuracy:  0.95 test_loss:  0.375 test_accuracy:  1.0\n",
      "epoch:  171 train_loss:  0.372 train_accuracy:  0.95 test_loss:  0.374 test_accuracy:  1.0\n",
      "epoch:  172 train_loss:  0.371 train_accuracy:  0.95 test_loss:  0.372 test_accuracy:  1.0\n",
      "epoch:  173 train_loss:  0.37 train_accuracy:  0.95 test_loss:  0.371 test_accuracy:  1.0\n",
      "epoch:  174 train_loss:  0.368 train_accuracy:  0.95 test_loss:  0.369 test_accuracy:  0.967\n",
      "epoch:  175 train_loss:  0.367 train_accuracy:  0.958 test_loss:  0.368 test_accuracy:  1.0\n",
      "epoch:  176 train_loss:  0.366 train_accuracy:  0.95 test_loss:  0.366 test_accuracy:  1.0\n",
      "epoch:  177 train_loss:  0.364 train_accuracy:  0.95 test_loss:  0.365 test_accuracy:  1.0\n",
      "epoch:  178 train_loss:  0.363 train_accuracy:  0.958 test_loss:  0.364 test_accuracy:  1.0\n",
      "epoch:  179 train_loss:  0.362 train_accuracy:  0.958 test_loss:  0.362 test_accuracy:  1.0\n",
      "epoch:  180 train_loss:  0.361 train_accuracy:  0.958 test_loss:  0.361 test_accuracy:  1.0\n",
      "epoch:  181 train_loss:  0.359 train_accuracy:  0.958 test_loss:  0.359 test_accuracy:  1.0\n",
      "epoch:  182 train_loss:  0.358 train_accuracy:  0.958 test_loss:  0.358 test_accuracy:  1.0\n",
      "epoch:  183 train_loss:  0.357 train_accuracy:  0.95 test_loss:  0.356 test_accuracy:  1.0\n",
      "epoch:  184 train_loss:  0.355 train_accuracy:  0.95 test_loss:  0.355 test_accuracy:  1.0\n",
      "epoch:  185 train_loss:  0.354 train_accuracy:  0.95 test_loss:  0.354 test_accuracy:  1.0\n",
      "epoch:  186 train_loss:  0.353 train_accuracy:  0.958 test_loss:  0.352 test_accuracy:  1.0\n",
      "epoch:  187 train_loss:  0.352 train_accuracy:  0.95 test_loss:  0.351 test_accuracy:  1.0\n",
      "epoch:  188 train_loss:  0.351 train_accuracy:  0.958 test_loss:  0.35 test_accuracy:  1.0\n",
      "epoch:  189 train_loss:  0.349 train_accuracy:  0.95 test_loss:  0.348 test_accuracy:  1.0\n",
      "epoch:  190 train_loss:  0.348 train_accuracy:  0.958 test_loss:  0.347 test_accuracy:  1.0\n",
      "epoch:  191 train_loss:  0.347 train_accuracy:  0.958 test_loss:  0.346 test_accuracy:  1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  192 train_loss:  0.346 train_accuracy:  0.967 test_loss:  0.344 test_accuracy:  1.0\n",
      "epoch:  193 train_loss:  0.344 train_accuracy:  0.958 test_loss:  0.343 test_accuracy:  1.0\n",
      "epoch:  194 train_loss:  0.343 train_accuracy:  0.958 test_loss:  0.342 test_accuracy:  1.0\n",
      "epoch:  195 train_loss:  0.342 train_accuracy:  0.958 test_loss:  0.34 test_accuracy:  1.0\n",
      "epoch:  196 train_loss:  0.341 train_accuracy:  0.958 test_loss:  0.339 test_accuracy:  1.0\n",
      "epoch:  197 train_loss:  0.34 train_accuracy:  0.967 test_loss:  0.338 test_accuracy:  1.0\n",
      "epoch:  198 train_loss:  0.339 train_accuracy:  0.95 test_loss:  0.336 test_accuracy:  1.0\n",
      "epoch:  199 train_loss:  0.337 train_accuracy:  0.95 test_loss:  0.335 test_accuracy:  1.0\n"
     ]
    }
   ],
   "source": [
    "##迭代\n",
    "\n",
    "##设置四个列表储存每次迭代时训练集和测试集的准确率和损失\n",
    "train_loss=[]\n",
    "train_accuracy=[]\n",
    "test_loss=[]\n",
    "test_accuracy=[]\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for x,y in train:#遍历每一个iteration\n",
    "        y_out = net(x)\n",
    "        loss = loss_func(y_out,y)#计算每一个iteration的损失\n",
    "        optimizer.zero_grad()#梯度设为0\n",
    "        loss.backward()#反向传播求解梯度\n",
    "        #优化\n",
    "        optimizer.step()\n",
    "    with torch.no_grad():\n",
    "        trainAccuracy = accuracy(net(trainData),trainLable)\n",
    "        trainLoss = loss_func(net(trainData),trainLable).data\n",
    "        testAccuracy = accuracy(net(testData),testLable)\n",
    "        testLoss = loss_func(net(testData), testLable).data\n",
    "        print('epoch: ',epoch,'train_loss: ',round(trainLoss.item(),3),'train_accuracy: ',round(trainAccuracy.item(),3),\n",
    "              'test_loss: ',round(testLoss.item(),3),'test_accuracy: ',round(testAccuracy.item(),3)\n",
    "              )\n",
    "        train_loss.append(trainLoss)\n",
    "        train_accuracy.append(trainAccuracy)\n",
    "        test_loss.append(testLoss)\n",
    "        test_accuracy.append(testAccuracy)\n",
    "        \n",
    "plt.plot(range(1,epochs+1),train_loss,label='train_loss')\n",
    "plt.plot(range(1,epochs+1),test_loss,label='test_loss')\n",
    "plt.plot(range(1,epochs+1),train_acc,label='train_acc')\n",
    "plt.plot(range(1,epochs+1),test_acc,label='test_acc')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
